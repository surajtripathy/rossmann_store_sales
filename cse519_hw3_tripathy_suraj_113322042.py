# -*- coding: utf-8 -*-
"""Assignment_3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cHJEo7G6sDdKs0gozOgYKc1LUpgiTwfW

## **Mounting drive and import statements**

- Mount google drive and import libraries
"""

# Commented out IPython magic to ensure Python compatibility.
## To load up drive

# %cd drive/MyDrive/CSE_519_assignment/hw3

## Import statements

import numpy as np
import pandas as pd
import seaborn as sns
import os
from sklearn import metrics
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import datetime
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.model_selection import permutation_test_score
from scipy import stats

root_dir = os.getcwd()
pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', None)

"""## **Q1Reading store data and train data, visualization and data combination**

- Read store data, train data, test data.
- Check missing elements and handle them(Drop, fill with mean).
- Merge store data with train data into a single dataframe. 
"""

store_df = pd.read_csv(root_dir + "/store.csv")

train_df = pd.read_csv(root_dir + "/train.csv")

test_df = pd.read_csv(root_dir + "/test.csv")

store_df.shape

train_df.shape

store_df.head()

train_df.head()

train_df.describe()

store_df.describe()

missing = train_df.isnull().sum()
missing.sort_values(ascending=False)

train_df['SalesPerCustomer'] = train_df['Sales']/train_df['Customers']

train_df.dropna(inplace=True)

store_df.isnull().sum()

store_df['CompetitionDistance'].fillna(store_df['CompetitionDistance'].mean(), inplace = True)

store_df.fillna(0, inplace = True)

store_df.head()

train_df = train_df.merge(right=store_df, on='Store', how='left')

train_df.shape

train_df.head()

"""## **Converting string of date to datetime object and segregating to year, month, day, week_of_year, year_week**

"""

train_df['Date'] = pd.to_datetime(train_df["Date"])
train_df["year"] = train_df["Date"].dt.year
train_df["month"] = train_df["Date"].dt.month
train_df["day"] = train_df["Date"].dt.day
train_df["week_of_year"] = train_df["Date"].dt.isocalendar().week
train_df["year_week"] = train_df["Date"].dt.strftime("%Y-%W")

train_df.hist(figsize=(20,12), legend=True)
plt.show()

"""## **Analysis of different type of holidays with sales**
- Combining "0" with 0 and making single entity.
- Plotting sales on holidays vs all days
- Take out 3 categories of holidays(holiday_a, holiday_b, holiday_c)
- Compute sales a week before each date belonging to each category.
- Plot the above calculation with the sales on the aggregation on holidays
"""

train_df['StateHoliday'].unique()

train_df["StateHoliday"].loc[train_df["StateHoliday"] == 0] = "0"

train_df['SchoolHoliday'].unique()

## Holidays + no_holidays
sns.barplot(x='StateHoliday', y='Sales', data=train_df)

## Holidays only
mask = (train_df["StateHoliday"] != "0") & (train_df["Sales"] > 0)
sns.barplot(x='StateHoliday', y='Sales', data=train_df[mask])

"""## Find how much sales each type of StateHoliday has"""

sales_per_day = train_df.groupby(['Date', 'StateHoliday']).agg({'Sales': 'sum'}).reset_index()
sales_per_day.head()

holidays_df = sales_per_day[sales_per_day['StateHoliday'] != "0"]
holiday_a = holidays_df[holidays_df['StateHoliday']=='a']
holiday_b = holidays_df[holidays_df['StateHoliday']=='b']
holiday_c = holidays_df[holidays_df['StateHoliday']=='c']
non_holidays = sales_per_day[sales_per_day['StateHoliday'] == "0"]

"""## Helper function to check 7 days before holiday and plot the sales against the sales of the holiday"""

def compute_sales_for_previous_days(df, type):
  dates = df['Date'].to_list()
  temp_df = pd.DataFrame(columns=['Date', 'Before_Holidays', 'During_Holidays'])
  days = datetime.timedelta(7)
  for date in dates:
    prev_date = date - days
    sales = non_holidays[(non_holidays['Date'] >= prev_date) & (non_holidays['Date'] < date)]['Sales'].sum()
    temp_df = temp_df.append({'Date': date, 'Before_Holidays': int(df[df['Date'] == date]['Sales'].values), 'During_Holidays': sales}, ignore_index=True)
  temp_df["During_Holidays"] = temp_df["During_Holidays"]/25
  temp_df.plot(x='Date', y=['Before_Holidays', 'During_Holidays'], kind='bar')

compute_sales_for_previous_days(holiday_a,"a")

compute_sales_for_previous_days(holiday_b,"b")

compute_sales_for_previous_days(holiday_c,"c")

"""## **Calculation of the top 5 and bottom 5 stores on basis of sales**
- Group stores on basis of sum of sales and sort them
- Take out the top 5 and bottom 5
"""

sales_per_store = train_df.groupby(['Store', 'Date']).agg({'Sales': 'sum'}).reset_index()
sales_per_store.head()

sorted_sales = sales_per_store.sort_values(['Sales'], ascending=False)
sorted_sales.head()

top_five = sorted_sales[:5]
print(top_five)

bottom_five = sorted_sales[-5:]
print(bottom_five)

"""## **Plotting the 5 top and 5 bottom stores on bases of sales with respect to sales of each week**
- For each store, group it's sales by week_of_year and year_week and plot it against the sales
"""

for store in top_five["Store"].to_list():
  df = train_df[train_df["Store"] == store]
  grouped_by_week_df = df[['week_of_year', 'year_week', 'Sales']].groupby(['year_week', 'week_of_year']).agg({'Sales': 'sum'}).reset_index()
  label = f"Store - {store}"
  sns.lineplot(x='week_of_year', y="Sales", data=grouped_by_week_df, label=label)
  plt.show()

for store in bottom_five["Store"].to_list():
  df = train_df[train_df["Store"] == store]
  grouped_by_week_df = df[['week_of_year', 'year_week', 'Sales']].groupby(['year_week', 'week_of_year']).agg({'Sales': 'sum'}).reset_index()
  label = f"Store - {store}"
  sns.lineplot(x='week_of_year', y="Sales", data=grouped_by_week_df, label=label)
  plt.show()

"""## **Analyzis of sales with competitors**
- First, we need to modify the types of the columns.
- Calculating since when the competition has been open and storing 0 if it's negative.
- Grouping based on store, competitionopen, competitiondistance and date - it will give us data related to competitors.
- Group the most near competitions and plot them.
"""

# competition
train_df['CompetitionOpenSinceMonth'] = train_df['CompetitionOpenSinceMonth'].astype( 'int64' )
train_df['CompetitionOpenSinceYear'] = train_df['CompetitionOpenSinceYear'].astype( 'int64' )

train_df['CompetitionOpen'] = 12 * (train_df['year'] - train_df['CompetitionOpenSinceYear']) + (train_df['month'] - train_df['CompetitionOpenSinceMonth'])
train_df['CompetitionOpen'] = train_df['CompetitionOpen'].map(lambda x: 0 if x < 0 else x)

competitor_data = train_df.groupby(['Store', 'Date', 'CompetitionDistance',	'CompetitionOpen']).agg({'Sales': 'sum'}).reset_index()
competitor_data.head()

competitor_data["week_of_year"] = competitor_data["Date"].dt.isocalendar().week
competitor_data["year_week"] = competitor_data["Date"].dt.strftime("%Y-%W")
competitor_data.head()

sales_per_week = competitor_data.groupby(['week_of_year', 'year_week', 'Store', 'CompetitionDistance', 'CompetitionOpen']).agg({'Sales': 'sum'}).reset_index()
sales_per_week.head()

plot_df = sales_per_week.groupby(['CompetitionDistance','CompetitionOpen']).agg({'Sales': 'mean'}).reset_index()
plot_df.head()

label = "Sales per week vs Distance to nearest competitor"
sns.lineplot(x='CompetitionDistance', y='Sales', data=plot_df, label=label)

"""## **Plotting pearson correlation for 5 most interesting features**"""

df_correlation = train_df[["Sales", "CompetitionOpen", "SalesPerCustomer", "SchoolHoliday", "Promo", "DayOfWeek"]]

pear_corr = df_correlation.corr(method='pearson')
sns.heatmap(pear_corr)

spearman_corr = df_correlation.corr(method='spearman')
sns.heatmap(spearman_corr)

"""## **Train-test-validation split, permutation test, plots to show informative properties, RMSPE calculation helper function, etc**

- Splitting the train data into validation data and otherwise(Base of if it exists between May-July 2015
- Selecting features which we want to use for model training
- Helper functions to normalize values
- Converting Categorical values to numerical values
- Defined RMSPE helper function
- Doing a single linear regression on "StateHoliday", "Open", "DayOfWeek"
- Printed the RMSPE and p values for each

"""

validation_split_df = train_df[(train_df["Date"] > "2015-05-01") & (train_df["Date"] < "2015-07-31")]
validation_split_df.head()

train_split_df = train_df[(train_df["Date"] < "2015-05-01") | (train_df["Date"] > "2015-07-31")]
train_split_df.head()

features = ['DayOfWeek', 'Promo', 'Open', 'StateHoliday', 'SchoolHoliday', 'StoreType', 'Assortment', 'CompetitionDistance', 'CompetitionOpen']
target = ["Sales"]

"""## Helper function to normalize features of a dataframe"""

def normalize_feature(df, column_names_to_normalize):
  result = df.copy()
  for feature_name in column_names_to_normalize:
      max_value = df[feature_name].max()
      min_value = df[feature_name].min()
      result[feature_name] = (df[feature_name] - min_value) / (max_value - min_value)
  return result

train_split_df = normalize_feature(train_split_df, ["DayOfWeek", "CompetitionDistance", "CompetitionOpen"])
validation_split_df = normalize_feature(validation_split_df, ["DayOfWeek", "CompetitionDistance", "CompetitionOpen"])

print(train_split_df["Assortment"].unique())
print(train_split_df["StoreType"].unique())

"""## Converting categorical data to numerical format"""

train_split_df["StoreType"] = train_split_df['StoreType'].map(lambda x: 0 if x == "a" else (1 if x=="b" else (2 if x=="c" else 3)))
train_split_df["Assortment"] = train_split_df['Assortment'].map(lambda x: 0 if x == "a" else (1 if x=="b" else 2))
train_split_df["StateHoliday"] = train_split_df['StateHoliday'].map(lambda x: 0 if x == "0" else (1 if x=="1" else (2 if x=="2" else 3)))

validation_split_df["StoreType"] = validation_split_df['StoreType'].map(lambda x: 0 if x == "a" else (1 if x=="b" else (2 if x=="c" else 3)))
validation_split_df["Assortment"] = validation_split_df['Assortment'].map(lambda x: 0 if x == "a" else (1 if x=="b" else 2))
validation_split_df["StateHoliday"] = validation_split_df['StateHoliday'].map(lambda x: 0 if x == "0" else (1 if x=="1" else (2 if x=="2" else 3)))

train_split_df[features].head()

"""## Helper function to calculate RMSPE"""

def root_mean_sqr_err(y_act, y_pred):
  return np.sqrt(np.mean(np.square((y_act-y_pred)/y_act)))

Y = train_split_df[target]
train_split_df = train_split_df[features]

validation_Y = validation_split_df[target]
validation_split_df = validation_split_df[features]

train_split_df.head()

train_split_df.dtypes

X_train, X_test, y_train, y_test = train_test_split(train_split_df, Y, test_size=0.2, random_state=2, shuffle=True)

"""## Helper function to make linear regression and fit with single feature parameter"""

def single_regression(X_train, X_test, n_jobs = None, fit_intercept = None):
  if n_jobs and not fit_intercept:
    linear_reg = LinearRegression(n_jobs=n_jobs)
  elif fit_intercept and not n_jobs:
    linear_reg = LinearRegression(fit_intercept=fit_intercept)
  elif n_jobs and fit_intercept:
    linear_reg = LinearRegression(fit_intercept=fit_intercept, n_jobs=n_jobs)
  else:
    linear_reg = LinearRegression()
  linear_reg.fit(X_train, y_train.values.ravel())
  y_pred = linear_reg.predict(X_test)
  return y_pred, linear_reg

"""## Helper function to calculate the scores, RMSPE"""

def get_scores(X_train, X_test, y_pred, m, is_validation_required= False, validation_pred= None, p_score=None):
  print(f"Training score is {m.score(X_train, y_train.values.ravel())}")
  print(f"Test score is {m.score(X_test, y_test)}")
  if is_validation_required:
    print(f"Training RMSPE is {root_mean_sqr_err(y_test, y_pred)}")
    print(f"Validation score is {m.score(validation_split_df, validation_Y)}")
    print(f"Validation RMSPE is {root_mean_sqr_err(validation_Y, validation_pred)}")
  else:
    print(f"Training RMSPE is {root_mean_sqr_err(y_test.values.ravel(), y_pred)}")
  if p_score:
    score_rand, perm_scores_rand, pvalue_rand = permutation_test_score(m, X_test, y_test.values.ravel(), scoring="neg_root_mean_squared_error", cv=None, n_permutations=100)
    print(f"p value is {pvalue_rand}")

"""## Doing a single linear regression on "StateHoliday", "Open", "DayOfWeek"
## Printed the RMSPE and p values for each Q6

"""

y_pred, model = single_regression(X_train[["StateHoliday"]], X_test[["StateHoliday"]])
get_scores(X_train=X_train[["StateHoliday"]], X_test=X_test[["StateHoliday"]], y_pred=y_pred, m=model, p_score=True)

y_pred, model = single_regression(X_train[["Open"]], X_test[["Open"]])
get_scores(X_train=X_train[["Open"]], X_test=X_test[["Open"]], y_pred=y_pred, m=model, p_score=True)

y_pred, model = single_regression(X_train[["DayOfWeek"]], X_test[["DayOfWeek"]])
get_scores(X_train=X_train[["DayOfWeek"]], X_test=X_test[["DayOfWeek"]], y_pred=y_pred, m=model, p_score=True)



"""## **Continuing with interesting plots for five informative data-Q7**
- How much sales happened every Week of year(lineplot)
- How much sales happened by day(Histplot)
- How much sales happened by storetype(boxplot)
- How much sales happened by category of promo(Boxplot)
- How many customers wrt sales(Scatterplot)


"""

group_by_month = train_df.groupby(["week_of_year"]).sum().reset_index()
sns.lineplot(data=group_by_month, y="Sales", x="week_of_year")

sns.histplot(data=train_df, y="Sales", x="DayOfWeek")

sns.boxplot(data=train_df, y="Sales", x="StoreType")

promo_df = train_df.groupby(["Promo"]).sum().reset_index()

sns.barplot(data=promo_df, y="Sales", x="Promo")

interesting_df = train_df.groupby(["Customers"]).sum().reset_index()
sns.scatterplot(data=interesting_df, y="Customers", x="Sales")



"""## **Contuining Model building Q8**
- Linear Regression
- Random Forest Regressor
"""

y_pred, model = single_regression(X_train, X_test)
get_scores(X_train, X_test, y_pred, model)

"""## **Hyper Paramter tunings**
- n_estimators(Number of trees)
- max_depth(max depth of each tree)
- n_jobs(how many processes) -1 means max number
- min_samples_leaf(The minimum number of samples required to be at a leaf node)
- max_features(Randomly sample columns at each split)

Increasing the max_depth and the min_samples_leaf increases the training time. Other scores are printed below

## **Q9 - Also doing the t-test for individual model below-**
"""

m = RandomForestRegressor(n_estimators=1, max_depth=3, bootstrap=False, n_jobs=-1)
m.fit(X_train, y_train.values.ravel())
y_pred = m.predict(X_test)
y_pred = np.expand_dims(y_pred, axis=1)
validation_pred = m.predict(validation_split_df)
validation_pred = np.expand_dims(validation_pred, axis=1)
get_scores(X_train=X_train, X_test=X_test, y_pred=y_pred, m=m, is_validation_required=True, validation_pred=validation_pred)

print(stats.ttest_ind(y_pred, y_test))

m = RandomForestRegressor(n_estimators=40, max_depth=3, bootstrap=False, n_jobs=-1)
m.fit(X_train, y_train.values.ravel())
y_pred = m.predict(X_test)
y_pred = np.expand_dims(y_pred, axis=1)
validation_pred = m.predict(validation_split_df)
validation_pred = np.expand_dims(validation_pred, axis=1)
get_scores(X_train=X_train, X_test=X_test, y_pred=y_pred, m=m, is_validation_required=True, validation_pred=validation_pred)

print(stats.ttest_ind(y_pred, y_test))

m = RandomForestRegressor(n_estimators=40, min_samples_leaf=2, max_features=0.99, n_jobs=-1)
m.fit(X_train, y_train.values.ravel())
y_pred = m.predict(X_test)
y_pred = np.expand_dims(y_pred, axis=1)
validation_pred = m.predict(validation_split_df)
validation_pred = np.expand_dims(validation_pred, axis=1)
get_scores(X_train=X_train, X_test=X_test, y_pred=y_pred, m=m, is_validation_required=True, validation_pred=validation_pred)

print(stats.ttest_ind(y_pred, y_test))





"""## **Q10-Doing the same preprocessing steps for the test dataframe**
- Use the linear regression model to predict and save the output as lr_answer.csv
- Use the random forest model to predict and save the output as rr_answer.csv
"""



test_df.head()

missing = test_df.isnull().sum()
missing.sort_values(ascending=False)

test_df.fillna(0, inplace = True)
test_df = test_df.merge(right=store_df, on='Store', how='left')

test_df['Date'] = pd.to_datetime(test_df["Date"])
test_df["year"] = test_df["Date"].dt.year
test_df["month"] = test_df["Date"].dt.month
test_df["day"] = test_df["Date"].dt.day
test_df["week_of_year"] = test_df["Date"].dt.isocalendar().week
test_df["year_week"] = test_df["Date"].dt.strftime("%Y-%W")

test_df['CompetitionOpen'] = 12 * (test_df['year'] - test_df['CompetitionOpenSinceYear']) + (test_df['month'] - test_df['CompetitionOpenSinceMonth'])
test_df['CompetitionOpen'] = test_df['CompetitionOpen'].map(lambda x: 0 if x < 0 else x)

test_df.head()

test_features = ['DayOfWeek', 'Promo', 'Open', 'StateHoliday', 'SchoolHoliday', 'StoreType', 'Assortment', 'CompetitionDistance', 'CompetitionOpen']

test_df = normalize_feature(test_df, ["DayOfWeek", "CompetitionDistance", "CompetitionOpen"])

test_df["StoreType"] = test_df['StoreType'].map(lambda x: 0 if x == "a" else (1 if x=="b" else (2 if x=="c" else 3)))
test_df["Assortment"] = test_df['Assortment'].map(lambda x: 0 if x == "a" else (1 if x=="b" else 2))
test_df["StateHoliday"] = test_df['StateHoliday'].map(lambda x: 0 if x == "0" else (1 if x=="1" else (2 if x=="2" else 3)))

answer = test_df[["Id"]].copy()
test_df = test_df[test_features]

test_df.head()

y_pred_l_regg = model.predict(test_df)

answer["Sales"] = y_pred_l_regg
answer.to_csv(root_dir+"/lr_answer.csv",chunksize=1000, index=False)

y_pred_rr = m.predict(test_df)

answer["Sales"] = y_pred_l_regg
answer.to_csv(root_dir+"/rr_answer.csv",chunksize=1000, index=False)

